<!--- GENERATED by .codex codex-sync. Do not edit directly. --->

# Workspace Rules for Coding Agents (Codex-ready)

> This file is concatenated from `code/.codex/*.md` in numeric order so Codex can read one page per directory.


# Core Rule

> **Every code change must stay in sync with docs, reference terminology, and kanban.**

If you add/change/remove behavior, you MUST update:
- Relevant **system-design docs**
- **Reference terminology** (if semantics change)
- The corresponding **kanban card(s)**


# Project Map (what lives where)

_All paths relative to `code/`._

## Kanban
- `docs/kanban/**/*.md` (mirrored into `docs/book/src/kanban/**` via `cargo make docs-sync`)

## Reference terminology
- `docs/reference-terminology/semantic-relationships.yaml`  
  Keep semantic relationships (synonym, hypernym, mapping states) consistent with code & docs.

## System-design docs

### Base / workspace layout
- `docs/system-design/base/directory-architecture.md` � **Read this first** to pick crate homes.  
  Buckets: `app/`, `domain/`, `platform/`.

### FHIR system (selected)
- Architecture: `docs/system-design/fhir/architecture/system-architecture.md`
- Behavior: `docs/system-design/fhir/behavior/sequence-servicerequest.md`, `state-servicerequest.md`
- Models: `docs/system-design/fhir/models/class-model.md`, `data-model-er.md`
- Overview: `docs/system-design/fhir/overview.md` / `index.md`

### NCIt mapping system (selected)
- Architecture: `docs/system-design/ncit/architecture/system-architecture.md`, `architecture.md`
- Behavior: `docs/system-design/ncit/behavior/sequence-servicerequest.md`, `state-servicerequest.md`
- Models: `docs/system-design/ncit/models/class-model.md`, `data-model-er.md`
- Overview: `docs/system-design/ncit/index.md`

## Workspace tooling
- `Makefile.toml` + `data/makefiles/` � standardized cargo-make tasks
- `docs/book/` � mdBook sources and built HTML
- `docs/runbook/` � runbooks (synced into the mdBook)
- `data/environment/` � `.env.*.example` templates (loader: `dfps_configuration`)

## Binary entrypoint
- `src/main.rs` � if used; may compose `lib/pipeline` etc.


# General Workflow (Feature / Refactor / Bugfix)

1) **Locate the kanban file**
   - Domain/fake_data/test skeleton ? `docs/kanban/feature-base-skeleton.md`
   - FHIR ingestion MVP ? `docs/kanban/feature-fhir-pipeline-mvp.md`
   - NCIt mapping skeleton ? `docs/kanban/feature-mapping-ncit-skeleton.md`

2) **Read system-design first**
   - FHIR ? `docs/system-design/fhir/**`
   - NCIt ? `docs/system-design/ncit/**`
   - Workspace layout ? `docs/system-design/base/directory-architecture.md`
   - Semantics ? `docs/reference-terminology/semantic-relationships.yaml`

3) **Plan the change**
   - Decide crates/modules to touch
   - Identify which docs & kanban cards must be updated (create a new card if none fits)

4) **Implement**
   - Respect bounded contexts:
     - Domain invariants ? `lib/domain/core`
     - Generators ? `lib/domain/fake_data`
     - FHIR transforms ? `lib/domain/ingestion`
     - Mapping engine ? `lib/domain/mapping`
     - Orchestration ? `lib/domain/pipeline`

5) **Update tests**
   - Unit tests (per crate)
   - Integration & e2e in `lib/platform/test_suite/tests/**`
   - Regression fixtures under `lib/platform/test_suite/fixtures/regression/`

6) **Run standard checks**
   - `cargo make fmt` � `cargo make clippy` � `cargo make test`
   - If docs changed: `cargo make docs` (builds mdBook after `docs-sync`)

7) **Update docs, terminology, kanban**
   - Keep behavior and flows aligned; run `docs-sync` + `docs`
   - Update `semantic-relationships.yaml` if semantics changed
   - Move kanban cards across columns; don�t rewrite checklists�check them off


# Kanban Version Sync (Lightweight, Docs‑Only)

**Scope:** applies when modifying any file under `docs/kanban/**`.  
**Goal:** keep **epic-level** versioning in sync **without** bumping Cargo versions on every checkbox.

---

## When you check off a Kanban item

Every time you change a checklist line from `- [ ]` to `- [x]` in `docs/kanban/**`:

1) **Read the current workspace version** from `code/Cargo.toml` -> `[workspace.package].version`.  
   If missing, write `Unreleased` instead of a version number for the steps below.

2) **Update the epic header** in the Kanban you touched:
   - If the epic is newly started and its “Introduced in” is `2025-11-15`, set it to the current workspace version (or `Unreleased` if no version chosen yet).
   - Always set **“Last updated in”** to the current workspace version (or `Unreleased`).

   Example:
   ```markdown
   > Status: **In progress**  
   > Introduced in: `v0.2.0`  
   > Last updated in: `v0.2.1`
   ```

3) **Update the cross‑epic index** at `docs/kanban/_epic_versions.yaml`.  
   Ensure the epic ID is present with `introduced_in` and `last_updated_in`.

   ```yaml
   epics:
     FP-07:
       introduced_in: v0.2.0
       last_updated_in: v0.2.1
     MAP-09:
       introduced_in: v0.2.0
       last_updated_in: v0.2.1
   ```

4) **Add/refresh an Unreleased changelog entry** in `CHANGELOG.md` referencing the epic and the exact checklist line you checked:
   ```markdown
   ## [Unreleased]
   ### Changed
   - FP-07 – “Normalize ServiceRequest.status casing” (checkbox completed)
   ```

5) **Commit message**  
   Use a docs‑scoped commit that cites the epic:
   ```
   docs(FP-07): check off “Normalize status casing”; update epic header, versions index, changelog
   ```

> **No code version bump here.** Actual **SemVer** bumps (patch/minor/major) only happen in release PRs or when the change meets your breaking/feature criteria. See “Release flow” below.

---

## Release flow (when you *do* bump versions)

1) Decide the bump: **patch** for backward‑compatible fixes, **minor** for added functionality, **major** for breaking changes.  
2) Update `[workspace.package].version` at `code/Cargo.toml` and switch all `Unreleased` epic headers/entries that shipped in this release to that version.  
3) Convert `## [Unreleased]` bullets into a final `## [X.Y.Z] – YYYY‑MM‑DD` section.  
4) Tag: `git tag -a vX.Y.Z -m "..."; git push origin vX.Y.Z`.

*(SemVer definitions; Keep‑a‑Changelog section structure.)*


# Kanban Maintenance

## Card ID prefixes
- Base skeleton: `DM-xx`, `WS-xx`, `FD-xx`, `TS-xx`
- FHIR pipeline: `FP-xx`
- NCIt mapping: `MAP-xx`

## Adding a card (example)
```markdown
### FP-07 � Validatio& & error surface
- [ ] Add `IngestionError` in `lib/domain/ingestion/src/transforms.rs`
- [ ] Update FHIR semantics in `docs/system-design/fhir/behavior/sequence-servicerequest.md`
- [ ] Add regression fixtures under `lib/platform/test_suite/fixtures/regression/`
- [ ] Document error codes in `docs/reference-terminology/semantic-relationships.yaml`
```

## Columns

* **TODO ? INPROGRESS**: implementation starts
* **INPROGRESS ? REVIEW**: code + tests + initial docs written; pass locally
* **REVIEW ? DONE**: acceptance criteria met, docs fully synced


# System-Design ? Code ? Terminology (Traceability)

**Goal:** bi-directional links across code, docs, and terminology.

## From code to docs
Add `//!` headers on significant modules, linking to the exact docs and terminology entries:
```rust
//! NCIt mapping engine and ranking pipeline.
//! See:
//! - docs/system-design/ncit/architecture/system-architecture.md
//! - docs/system-design/ncit/models/class-model.md
//! - docs/system-design/ncit/behavior/state-servicerequest.md
//! - docs/reference-terminology/semantic-relationships.yaml
```

## From docs to code

When updating system-design docs, list the concrete modules they map to (e.g., ingestion transforms, mapping types, e2e test paths).

## Terminology schema linkage

When mapping states/semantics change:

* Update `docs/reference-terminology/semantic-relationships.yaml` with names, directionality, usage
* Add explicit references from docs and code headers to the updated YAML keys


# Acceptance & Quality Gates

A change is acceptable only if:

1. **Tests** - Unit/integration/e2e/property tests updated; `cargo test --all` passes
2. **Formatting & linting** - `cargo fmt --all` and `cargo clippy --all-targets -- -D warnings`
3. **Docs & terminology** - System-design docs updated; terminology consistent; module `//!` headers present
4. **Kanban** - Cards in correct columns; new work discovered is captured as TODO cards with IDs


# Branching & Commit Conventions

## Branching
- Base: `main`; prefer **one card -> one feature branch**.

**Name**
```
<kind>/<card-id>-kebab-summary
```
Where `<kind>` ∈ {`feature`, `bugfix`, `chore`, `docs`, `spike`} and `<card-id>` is the epic/card ID in Kanban (e.g., `FP-07`, `MAP-03`).

**Branch ↔ Epic binding (required)**
- The **active Git branch must be recorded in the epic Kanban** you are working on.
- In the epic header, add or update:
  - `Branch: <branch-name>`
  - `Branch target version: <semver or Unreleased>`
- If the branch name does **not** contain the `<card-id>`, rename the branch to match the convention or note the exception in the epic.

**Epic header example**
```markdown
> Epic: FP-07 – Ingestion error surface
> Branch: feature/FP-07-ingestion-error-surface
> Branch target version: v0.2.1
> Status: INPROGRESS
> Introduced in: 2025-11-15
> Last updated in: v0.2.1
```

## Workflow

1. **TODO -> INPROGRESS**
   - Create the branch from `main` using the naming rule.
   - In the epic Kanban, ensure the header contains:
     - `Branch: <branch-name>`
     - `Branch target version: Unreleased` (or seed with the planned semver)
     - `Status: INPROGRESS`

2. **Implement**
   - Code + tests + docs as usual.

3. **INPROGRESS -> REVIEW or DONE (leaving INPROGRESS)**
   - **Update the branch target version in the epic** (metadata only; do **not** bump Cargo here):
     - **PATCH** - routine/internal change
     - **MINOR** - user‑visible addition
     - **MAJOR** - breaking change
   - Set `Last updated in` to that version.
   - Keep `Introduced in: 2025-11-15` until a release PR.

4. **Merge -> `main`**
   - Move the card to **DONE**.
   - In the epic header, mark it as **included in the upcoming release** (e.g., add `Release: Upcoming` or an equivalent line).
   - Add/refresh a `## [Unreleased]` item in `CHANGELOG.md` referencing the epic ID and the **Branch target version**.

> **Note:** The workspace SemVer in `Cargo.toml` is only bumped in a **release PR** that collects all “Upcoming” epics. Until then, the epic carries the **Branch target version** as intent.

## Commits

**Format**
```
<type>(<card-id>[:<scope>]): short imperative summary
```
`<type>` ∈ {`feat`, `fix`, `refactor`, `chore`, `docs`, `test`, `ci`}

**Examples**
```
feat(FP-07:ingestion): add IngestionError enum and error mapping
fix(MAP-05:mapping): correct NCIt concept id for PET code 78815
docs(DM-05): document core domain model and invariants
```

**Body tips**
- Bullet points of cross‑cutting changes
- Mention updated docs/fixtures
- `Tests:` line with what ran
- If Kanban metadata changed, note it explicitly, e.g.:
  - `Kanban: record Branch=feature/FP-07-...`
  - `Kanban: set Branch target version -> v0.2.1`
  - `CHANGELOG: add Unreleased entry (FP-07)`

## Pre‑merge checklist
- Epic Kanban has `Branch:` recorded and `Branch target version` set
- Card moved to **DONE**; epic marked **Upcoming** (or equivalent)
- `CHANGELOG.md` updated under `[Unreleased]`
- `cargo make fmt` · `cargo make clippy` · `cargo make test` all passing


# Example Agent Flow

**Request:** �Add a new mapping state �HeuristicMatch� between NeedsReview and AutoMapped.�

Steps
1) Kanban � Add/Update card `MAP-09 � Add HeuristicMatch mapping state`
2) Read � NCIt state/behavior doc+ + terminology YAM+ + directory architecture
3) Modify � `lib/domain/core/src/mapping/mod.rs`, `lib/domain/mapping/src/lib.rs`
4) Tests � `lib/platform/test_suite/tests/unit/mapping_properties.rs`, e2e as needed
5) Run � fmt, clippy, test
6) Docs � Update NCIt behavior doc+ + terminology YAML
7) Kanban � Move `MAP-09` to **REVIEW**/**DONE** with brief note


# Codex Compatibility Notes

- **Discovery & precedence.** Codex concatenates instruction files in order: global (~/.codex) then project root ? subdirs on the path to CWD. Per directory Codex includes at most **one** file, preferring `AGENTS.override.md` then `AGENTS.md`, then fallback names. (Codex docs)
- **Size limits.** The combined project instruction slice is capped (`project_doc_max_bytes`, 32 KiB by default). Split large guidance across nested directories or raise the cap in config. (Codex docs)
- **Fallback names.** Customize with `project_doc_fallback_filenames` in `~/.codex/config.toml` (or your chosen `CODEX_HOME`).
- **Launching with a local profile.** You can point `CODEX_HOME` at `code/.codex` for repo-specific config.
- **Prompting best practices for agents.** Provide clear file/symbol pointers; include verification steps (`fmt`, `clippy`, `test`, mdBook build); split large tasks. (Codex prompting guide)

References:
- Custom instructions & discovery: Codex �Custom instructions with AGENTS.md�.
- Prompting patterns: Codex �Prompting guide�.


## Crate Responsibilities

# Crate: lib/app/cli — `dfps_cli`

**Purpose**  
Small CLIs for local ingestion + mapping workflows.

**Env & logging**
- Loads `app.cli` via `dfps_configuration`.
- `env_logger` with `--log-level` on `map_bundles`.

**Bins**
- **`map_bundles`** — read Bundle(s) (object/array/NDJSON) from file/stdin → emit rows.
  - Output (NDJSON to stdout; each line wraps the record):
    - `{"kind":"validation_issue", ...}`
    - `{"kind":"staging_flat", ...}`
    - `{"kind":"staging_code", ...}`
    - `{"kind":"mapping_result", ...}`
    - `{"kind":"dim_concept", ...}` (deduped by `ncit_id`)
    - `{"kind":"metrics_summary", ...}` (final)
  - Logs pipeline summaries and `NoMatch` reasons via `dfps_observability`.
  - Example:
    ```bash
    cd code
    cargo run -p dfps_cli --bin map_bundles -- ./bundle.ndjson
    ```
- **`map_codes`** — map `StgSrCodeExploded` rows.
  - Flags: `--explain` (emit candidate explanations), `--explain-top N` (default 5).
  - Stdout: one `MappingResult` JSON per line (+ optional `{"kind":"explanation",...}`).
  - Stderr: summary (`total`, `by_code_kind`, `by_license_tier`).
  - Example:
    ```bash
    cd code
    cargo run -p dfps_cli --bin map_codes -- --explain --explain-top 5 ./codes.ndjson
    ```


# Crate: lib/app/web/backend/api — `dfps_api`

**Purpose**  
Axum HTTP API for mapping requests and metrics.

**Env & config**
- Loads `app.web.api` via `dfps_configuration`.
- `ApiServerConfig` (defaults): `DFPS_API_HOST=127.0.0.1`, `DFPS_API_PORT=8080`.
- `init_logging()` bootstraps `env_logger` once.

**Routes**
- `GET /health` → `{"status":"ok"}` (logs `request_id`)
- `GET /metrics/summary` → `PipelineMetrics`
- `POST /api/map-bundles` → `MapBundlesResponse`
  - Accepts: **Bundle object**, **array**, or **NDJSON**.
  - For each bundle: `bundle_to_mapped_sr` → aggregate `flats`, `exploded_codes`, `mapping_results`, `dim_concepts`.
  - Dedupes concepts by `ncit_id`; updates global `PipelineMetrics`.

**Errors**
- `400 invalid_json`, `422 invalid_fhir`, `500 internal_error` — all include `request_id`.

**Run**
```bash
cd code
cargo run -p dfps_api --bin dfps_api
```

**Notes**
- `parse_bundles` rejects empty/whitespace bodies; auto‑detects NDJSON.
- Warns per `NoMatch` via `dfps_observability::log_no_match`.


# Crate: lib/app/web/backend/datamart — `dfps_datamart`

**Purpose**  
Build a small star schema from `PipelineOutput` for analytics/UI rendering.

**Key types**
- `Dims { patients, encounters, codes, ncit }` (all deduped via `BTreeMap`)
- `DimPatient`, `DimEncounter`, `DimCode`, `DimNCIT`
- `FactServiceRequest { sr_id, patient_key, encounter_key, code_key, ncit_key, status, intent, description, ordered_at }`

**Keys**
- `DimPatientKey::from_patient_id`
- `DimEncounterKey::from_encounter_id`
- `DimCodeKey::from_code_element_id`
- `DimNCITKey::from_ncit_id` / `DimNCITKey::no_match()`

**Behavior**
- Code dims derive from `CodeElement::from(StgSrCodeExploded)`.
- Missing or `NoMatch` → `ncit_key = NO_MATCH` sentinel with `ncit_id="NO_MATCH"`.
- Returns `(Dims, Vec<FactServiceRequest>)`.

**Tests**
- Integrity + NO_MATCH sentinel coverage included.


# Crate: lib/app/web/frontend — `dfps_web_frontend`

**Purpose**  
Actix‑Web UI (HTMX + Tailwind) that talks to the backend.

**Env**
- Loads `app.web.frontend` via `dfps_configuration`.
- `AppConfig`:
  - `DFPS_FRONTEND_LISTEN_ADDR` (default `127.0.0.1:8090`)
  - `DFPS_API_BASE_URL` (default `http://127.0.0.1:8080`)
  - `DFPS_API_CLIENT_TIMEOUT_SECS` (default `15`)
  - `DFPS_DOCS_URL` (optional `/docs` redirect)

**Backend client**
- `GET /health` → `HealthResponse`
- `GET /metrics/summary` → `PipelineMetrics`
- `POST /api/map-bundles` → `MapBundlesResponse`
- Friendly `ClientError` → alert text for the UI.

**Routes**
- `GET /` — base page with health + metrics
- `POST /map/paste` — parse JSON from textarea; HTMX fragment swap
- `POST /map/upload` — multipart file read (UTF‑8 JSON only; **max 512 KiB**)
- `GET /docs` — redirect to `DFPS_DOCS_URL` if present, else 404

**UI**
- Results panel with `MappingResult` rows and state chips:
  - AutoMapped / Needs review / No match
- Metrics dashboard from `PipelineMetrics`
- “NoMatch explorer” (SR, code, reason)

**Run**
```bash
cd code
cargo run -p dfps_web_frontend --bin dfps_web_frontend
```

**Tests**
- Route tests w/ Wiremock backend
- Template rendering assertions (metrics + NoMatch)


# Crate: lib/domain/core - `dfps_core`

**Path:** `code/lib/domain/core`  
**Purpose:** canonical domain/FHIR/staging/mapping/value types with `serde` support.  
**Feature flags:** `dummy` (enables `fake` derives for many types).

## Responsibilities
- Define the **domain model** (entities, value objects) and **FHIR-minimal** structs.
- Provide **staging rows** used by ingestion and mapping.
- Provide **mapping domain types** (`CodeElement`, `MappingResult`, etc.).
- Keep all public types serializable + testable (JSON round‑trip, doc tests).

## Modules & key types
- `value/` - `PatientId`, `EncounterId`, `ServiceRequestId` newtypes.
- `patient/` - `Patient` aggregate (minimal, expandable).
- `encounter/` - `Encounter` entity linking patient to context.
- `order/` - `ServiceRequest` aggregate + `ServiceRequestStatus/Intent` enums.
- `fhir/` - minimal FHIR R4/R5 structs (`Bundle`, `ServiceRequest`, `Reference`, ...) + `Bundle::iter_servicerequests()`.
- `staging/` - `StgServiceRequestFlat`, `StgSrCodeExploded` for landing tables.
- `mapping/` - `CodeElement`, `MappingCandidate`, `MappingResult`, `MappingState`, `MappingThresholds`, `MappingSourceVersion`, `NCItConcept`, `DimNCITConcept`.

## Cross‑links
- FHIR flows & requirements: `docs/system-design/fhir/**`
- NCIt flows & states: `docs/system-design/ncit/**`
- Terminology semantics: `docs/reference-terminology/semantic-relationships.yaml`

## Tests
- Keep unit tests co‑located (e.g., `fhir::Bundle` iteration test, `mapping` ID stability).
- Prefer deterministic seeds when using `#[cfg(feature = "dummy")]` generators.


# Crate: lib/domain/fake_data - `dfps_fake_data`

**Path:** `code/lib/domain/fake_data`  
**Depends on:** `dfps_core` (with `dummy`), `rand`, `fake`, `serde(_json)`, `dfps_configuration`.

## Responsibilities
- Deterministic, **seeded** generators for domain + minimal FHIR.
- CLI tools for generating **scenarios** and **raw FHIR Bundles** as JSON/NDJSON.

## Modules & bins
- `value.rs` - ID/status/intent/description fakers; seeded helpers.
- `patient.rs`, `encounter.rs`, `order.rs` - domain entity generators.
- `scenarios.rs` - cohesive `ServiceRequestScenario { patient, encounter, service_request }`.
- `raw_fhir.rs` - fake **FHIR** `Patient`, `Encounter`, `ServiceRequest`, and `Bundle` with plausible codings (SNOMED/CPT/LOINC); includes normalization to keep intent/status coherent.
- `bin/generate_sample.rs` - emits **domain** scenarios (reads env via `dfps_configuration`).
- `bin/generate_fhir_bundle.rs` - emits **FHIR Bundle** NDJSON; supports `--seed`, `--count`.

## Conventions
- Always provide `*_with_seed` and `*_with_rng` for determinism.
- Prefer minimal surface area for FHIR mock data; keep display/system/code realistic.

## Tests
- Round‑trip serde tests where helpful.
- Keep RNG usage explicit in tests (`StdRng::seed_from_u64`).


# Crate: lib/domain/ingestion - `dfps_ingestion`

**Path:** `code/lib/domain/ingestion`  
**Depends on:** `dfps_core`, `serde(_json)`.

## Responsibilities
- Normalize **FHIR -> staging -> domain** (`ServiceRequest`) with clear, typed errors.
- Provide **validation** utilities aligned with FHIR ingestion requirements.
- Keep behavior predictable; **strict** vs **lenient** modes available.

## Public API (re‑exports in `lib.rs`)
- `reference::{reference_id, reference_id_from_str}` - parse `"Type/id"` from `Reference`.
- `transforms::{ sr_to_staging, sr_to_domain, bundle_to_staging(_with_validation), bundle_to_domain(_with_validation), IngestionError }`
- `validation::{ validate_bundle, validate_sr, ValidationMode, ValidationReport, ValidationIssue, ValidationSeverity, RequirementRef, Validated }`

## Key rules
- `IngestionError` surfaces missing/invalid fields, invalid resource types, invalid status/intent, decode failures, and **validation** failures.
- `ValidationMode::Strict` blocks bundles with errors; `Lenient` returns a report alongside values.
- `description_from_sr` falls back: `ServiceRequest.description` -> `code.text` -> first `coding.display` -> `"unspecified service request"`.

## Tests
- Unit tests cover invalid resource types, invalid status/intent, strict/lenient validation, and relationship checks (missing Patient/Encounter in Bundle).

## Cross‑links
- FHIR ingestion MVP: `docs/kanban/feature/002-fhir-pipeline-mvp.md`
- FHIR behavior & requirements: `docs/system-design/fhir/**`


# Crate: lib/domain/mapping — `dfps_mapping`

**Path:** `code/lib/domain/mapping`  
**Depends on:** `dfps_core`, `dfps_terminology`, `serde(_json)`.

## Responsibilities
- Map staging codes to **NCIt** concepts; keep logic **deterministic and local**.
- Combine lexical + vector mock rankers with a rule re‑ranker; use **UMLS cross‑refs** where available.
- Attach **license/source** metadata using `dfps_terminology`.

## Modules & data
- `data.rs`
  - `load_ncit_concepts()` → `Vec<(NCItConcept, DimNCITConcept)>` (embedded JSON).
  - `load_umls_xrefs()` → `HashMap<(system, code), UmlsXref>` (embedded JSON).
  - Version constants: `NCIT_DATA_VERSION`, `UMLS_DATA_VERSION`.
- `lib.rs`
  - Rankers: `LexicalRanker`, `VectorRankerMock`, `RuleReranker`.
  - Engine: `MappingEngine<L,V>` with `ranked_candidates()` and `explain()`.
  - API: `map_staging_codes(...)`, `map_staging_codes_with_summary(...)`, `explain_staging_code(...)`.
  - Summary: `MappingSummary { total, by_code_kind, by_license_tier }`.
  - Classification helpers: `classify(score, thresholds)` → `MappingState`.
  - Result assembly: `build_result_with_score(...)`, `source_versions()`.

## Behavior
- For (system, code) present in `umls_xrefs.json` → emit **rule‑based** high‑score mapping (`0.99`) with `reason = "umls_direct_xref"`.
- Else → combine lexical/vector candidates; `RuleReranker` nudges **NCIT** upward slightly.
- Final `MappingResult` includes `state` by threshold, `source_version`, and, via `terminology::EnrichedCode`, `license_tier` and `source_kind`.

## Tests
- Determinism checks for engine outputs.
- Data loaders parse and include expected rows.
- Summary tallies by `CodeKind` (`known_licensed_system`, `unknown_system`, etc.) and license tiers.

## Cross‑links
- NCIt architecture & states: `docs/system-design/ncit/**`
- Terminology/registry semantics: `docs/reference-terminology/semantic-relationships.yaml`


# Crate: lib/domain/pipeline — `dfps_pipeline`

**Path:** `code/lib/domain/pipeline`  
**Depends on:** `dfps_ingestion`, `dfps_mapping`, `dfps_core`, `dfps_observability` (logging), `serde(_json)`, `thiserror`, `log`, `env_logger`.

## Responsibilities
- Provide a **single façade** from FHIR `Bundle` → staging → mapping → NCIt dims.
- Keep orchestration thin; **no business logic** beyond composition and error plumbing.

## Public API
- `bundle_to_mapped_sr(bundle: &Bundle) -> Result<PipelineOutput, PipelineError>`
  - Output: `{ flats, exploded_codes, mapping_results, dim_concepts }`
  - Error: `PipelineError::Ingestion(dfps_ingestion::IngestionError)`

## Cross‑links
- FHIR quickstart & NCIt sequence: `docs/system-design/fhir/index.md`, `docs/system-design/ncit/behavior/sequence-servicerequest.md`

## Tests
- Add e2e tests as surfaces grow; today, lean on ingestion + mapping unit tests.


# Crate: lib/domain/terminology — `dfps_terminology`

**Path:** `code/lib/domain/terminology`  
**Depends on:** `dfps_core`, `serde`.

## Responsibilities
- Normalize and classify **code systems**; provide lightweight **registry** and **OBO** metadata.
- Bridge staging codes to enriched context (license tier, source kind, canonical system).
- Supply **value set** metadata for groupings used elsewhere.

## Modules & key types
- `registry.rs`
  - `list_code_systems()`, `lookup_codesystem(url)`, `is_licensed(url)`, `is_open(url)`.
  - Includes CPT, SNOMED CT, LOINC, and NCIt (OBO) entries.
- `codesystem.rs`
  - `CodeSystemMeta` + enums `LicenseTier { licensed | open | internal_only }`, `SourceKind { fhir | umls | obo_foundry | local }`.
- `bridge.rs`
  - `EnrichedCode::from_staging(StgSrCodeExploded)` → attaches `codesystem`, `license_tier`, `source_kind`, and a **canonical system URL**.
  - `CodeKind` classification: `KnownLicensedSystem | KnownOpenSystem | OboBacked | UnknownSystem | MissingSystemOrCode`.
  - Internal canonicalizer maps OIDs to URLs (e.g., SNOMED, LOINC).
- `obo.rs`
  - Minimal ontology records (`OboOntology`), list/lookup for NCIt/MONDO.
- `valueset.rs`
  - `ValueSetMeta` records for PET imaging subsets combining CPT/SNOMED, LOINC/NCIt.

## How mapping uses this
- `dfps_mapping` calls `EnrichedCode::from_staging(...)` to:
  - Classify by `CodeKind` for **summary** tallies.
  - Attach `license_tier`/`source_kind` into `MappingResult` for downstream filtering.

## Tests
- Verify known systems resolve with expected license/source attributes.
- Verify OBO lookups and value set presence.
- Keep canonicalization stable for OID → URL normalization.

## Cross‑links
- Terminology semantics & policies: `docs/reference-terminology/semantic-relationships.yaml`




# Crate: lib/platform/configuration — `dfps_configuration`

**Purpose**  
Workspace‑wide env loader. Resolves a namespaced `.env` and loads it with `dotenvy`.

**Primary API**
```rust
pub fn load_env(namespace: &str) -> Result<EnvLoadOutcome, EnvLoadError>;
```
- `namespace`: dotted path reflecting crate location (e.g., `app.web.api`).
- `EnvLoadOutcome { namespace, profile, files }`, where `profile` = `DFPS_ENV` → `APP_ENV` → `"dev"`.

**Resolution rules**
1. If `DFPS_ENV_FILE` is set → resolve relative to workspace root and load that file only.
2. Else search directories (in order):
   - `<workspace>/data/environment`
   - `<workspace>`
3. In each dir, try `.env.<namespace>.<profile>` then fallback `.env.<namespace>.local`.

**Workspace root discovery**
- `DFPS_WORKSPACE_ROOT` (if exists) or walk up from `current_dir()` until a `Cargo.lock` is found.

**Strict mode**
- If nothing loads **and** `DFPS_ENV_STRICT` or `CI` is truthy, return:
  `EnvLoadError::FileMissing { namespace, profile, attempted }`.

**Error variants**
```
CurrentDir(io::Error)
WorkspaceRootNotFound
DotEnv { path, source }
FileMissing { namespace, profile, attempted: Vec<PathBuf> }
```

**Notes & gotchas**
- Boolean envs: empty value counts as **true**; only `false|0|off` (case‑insensitive) are false.
- Paths are resolved relative to **workspace root**, not process CWD.

**Used by**
- `platform.observability`, `platform.test_suite`
- `app.cli`, `app.web.api`, `app.web.frontend`


# Crate: lib/platform/observability — `dfps_observability`

**Purpose**  
Shared logging + metrics for the Bundle → NCIt mapping pipeline.

**Env**
- Loads `platform.observability` via `dfps_configuration::load_env("platform.observability")`.

**Types & functions**
```rust
pub fn init_environment();

#[derive(Default, Serialize, Deserialize, Clone, PartialEq)]
pub struct PipelineMetrics {
  pub bundle_count: usize,
  pub flats_count: usize,
  pub exploded_count: usize,
  pub mapping_count: usize,
  pub auto_mapped: usize,
  pub needs_review: usize,
  pub no_match: usize,
}
impl PipelineMetrics {
  pub fn record(&mut self,
    flats: &[StgServiceRequestFlat],
    codes: &[StgSrCodeExploded],
    mappings: &[MappingResult],
  );
}

pub fn log_pipeline_output(
  flats: &[StgServiceRequestFlat],
  codes: &[StgSrCodeExploded],
  mappings: &[MappingResult],
  metrics: &mut PipelineMetrics,
);

pub fn log_no_match(result: &MappingResult);
```

**Logging targets**
- `dfps_pipeline` (info): per‑bundle summary (flats, mappings, cumulative state counts).
- `dfps_mapping` (warn): each `MappingState::NoMatch` with a reason.

**Used by**
- `dfps_cli`, `dfps_api`, tests in `dfps_test_suite`.


# Crate: lib/platform/test_suite — `dfps_test_suite`

**Purpose**  
Reusable fixtures/assertions and a full test harness (unit, integration, E2E) spanning ingestion → mapping → datamart → web API.

**Env**
- Eagerly loads `platform.test_suite` via `dfps_configuration`.
- `ping()` returns `"test-suite-ready"` post‑init.

**Exports**
- `assertions`:
  - `assert_json_roundtrip<T>(&T)`
  - `assert_service_request_integrity(&ServiceRequest)`
  - `assert_scenario_consistency(&ServiceRequestScenario)`
- `fixtures`:
  - Scenario builders (seeded helpers)
  - Mapping fixtures for CPT/SNOMED/NCIt/unknown (`mapping_*` fns)
- `regression`:
  - Accessors for embedded JSON fixtures:
    - `baseline_service_request()`
    - `baseline_fhir_bundle()`
    - `fhir_bundle_missing_subject()`
    - `fhir_bundle_invalid_status()`
    - `fhir_bundle_extra_codings()`
    - `fhir_bundle_uppercase_status()`
    - `fhir_bundle_unknown_code()`
    - `fhir_bundle_missing_encounter()`

**Test suites**
- **E2E** (`tests/e2e/`):
  - `fhir_ingest_flow.rs` — flats vs coding counts; ID normalization checks
  - `mapping_pipeline.rs` — end‑to‑end NCIt mapping (expects `NCIT:C19951`)
  - `observability_metrics.rs` — metrics snapshot after pipeline run
  - `service_request_flow.rs` — scenario invariants + serde round‑trip
- **Integration** (`tests/integration/`):
  - `fhir_ingest.rs` — strict validation errors/warnings (issue IDs)
  - `mapping.rs` — state + metadata (license_tier, source_kind)
  - `datamart.rs` — dims/facts wiring + `NO_MATCH` sentinel
  - `validation.rs` — missing subject/encounter/status cases
  - `web_api.rs` — `/api/map-bundles`, `/metrics/summary`, `/health` via Axum
- **Unit** (`tests/unit/`):
  - `mapping_properties.rs` — property‑based ranking invariants
  - `property_roundtrip.rs` — seeded scenario invariants

**Dev deps**
- `axum`, `tokio`, `reqwest`, `http-body-util`, `tower`
- `proptest` (property tests)

**Run**
```bash
cd code
cargo test -p dfps_test_suite
```

