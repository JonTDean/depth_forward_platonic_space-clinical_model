# Mapping Evaluation Quickstart

This runbook walks through running the mapping evaluation harness (Epic EVAL-012)
against the gold NDJSON fixtures.

## Prerequisites
- Rust toolchain (install via `data/scripts/install_rust_tooling.sh`).
- Gold dataset: `data/eval/pet_ct_small.ndjson` (or your custom NDJSON with `EvalCase` rows). Override the root with `DFPS_EVAL_DATA_ROOT` if you keep datasets elsewhere.
- Tiered splits: bronze/silver/gold datasets (e.g., `bronze_pet_ct_small`, `silver_pet_ct_extended`, `gold_pet_ct_comprehensive`) live under `data/eval/README.md`.

## Steps
1. Build/run the CLI using a named dataset
   ```bash
   cd code
   cargo run -p dfps_cli --bin eval_mapping -- \
     --dataset pet_ct_small \
     --dump-details
   ```
   (Use `--input <path>` instead if you want to point at a specific NDJSON file.)
2. Interpret output
   - Summary line: `{"kind":"eval_summary", ...}` includes `precision`, `recall`, counts.
   - Optional details: per-case `{"kind":"eval_result",...}` entries show whether each case was correct and include the `MappingResult` payload.
   - Calibration-style summaries land under `score_buckets`: each bucket represents a 0.1 score range and only includes MappingResults that produced an NCIt prediction, exposing how well the engine is calibrated per score band.
3. For custom gold sets, ensure each line matches:
   ```json
   {"system":"...","code":"...","display":"...","expected_ncit_id":"NCIT:Cxxxx"}
   ```
4. Optional: enforce thresholds in CI by supplying a JSON config:
   ```json
   {
     "min_precision": 0.95,
     "min_recall": 0.95,
     "min_f1": 0.95,
     "min_accuracy": 0.95,
     "min_auto_precision": 0.98
   }
   ```
   ```bash
   cargo run -p dfps_cli --bin eval_mapping -- \
     --dataset pet_ct_small \
     --thresholds config/eval_thresholds.json
   ```
   `min_accuracy` guards overall correctness (regardless of predictions) while `min_auto_precision` focuses on the AutoMapped band specifically.
5. Persist machine-readable artifacts for dashboards/CI (plus optional Markdown report):
   ```bash
   cargo run -p dfps_cli --bin eval_mapping -- \
     --dataset gold_pet_ct_comprehensive \
     --out-dir target/eval \
     --report target/eval/report.md \
     --dump-details
   ```
   This writes `eval_summary.json` + `eval_results.ndjson` under `target/eval/gold_pet_ct_comprehensive/`.
6. Use `jq`/scripts (or the generated report) to gate CI metrics or share summaries.

## Requirements references
- `docs/system-design/clinical/ncit/requirements/ingestion-requirements.md` (MAP_ACCURACY) now points to `eval_mapping` as the verification method.
